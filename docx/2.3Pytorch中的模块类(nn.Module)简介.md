模块在Pytorch深度学习模型的搭建过程中扮演者重要的角色，模块本身是一个类nn.Module，PyTorch的模型通过继承该类，在类的内部定义好模块的实例化（即：在初始化中定义模型结构与参数），通过前向计算调用子模块（在函数forward()中编写网络前向过程），最后实现深度学习模型的搭建，模块类的构建模型请看以下代码。

```python
import torch
import torch.nn as nn

class Model(nn.Module):
    def __init__(self, ...): # 定义类的初始化函数，...是用户的传入参数
        super(Model, self).__init__()
        ... # 根据传入的参数来定义子模块
    
    def forward(self, ...): # 定义前向计算的输入参数，...一般是张量或者其他的参数
        ret = ... # 根据传入的张量和子模块计算返回张量
        return ret
```
下面以一个由两个全连接层组成的感知机为例，介绍如何使用nn.Module构造模块化的神经网络。新建一个perception.py文件，内容如下：
```python
# -*- coding: utf-8 -*-
import torch
from torch import nn
# 首先建立一个全连接的子module，继承nn.Module
class Linear(nn.Module):
    def __init__(self, in_dim, out_dim):
        super(Linear, self).__init__()  # 调用nn.Module的构造函数
        # 使用nn.Parameter来构造需要学习的参数
        self.w = nn.Parameter(torch.randn(in_dim, out_dim))
        self.b = nn.Parameter(torch.randn(out_dim))
# 在forward中实现前向传播过程
    def forward(self, x):
        x = x.matmul(self.w)  # 使用Tensor.matmul实现矩阵相乘
        y = x + self.b.expand_as(x)  # 使用Tensor.expand_as()来保证矩阵形状一致
        return y

# 构建感知机类，继承nn.Module，并调用了Linear的子module
class Perception(nn.Module):
    def __init__(self, in_dim, hid_dim, out_dim):
        super(Perception, self).__init__()
        self.layer1 = Linear(in_dim, hid_dim)
        self.layer2 = Linear(hid_dim, out_dim)
    def forward(self, x):
        x = self.layer1(x)
        y = torch.sigmoid(x)  # 使用torch中的sigmoid作为激活函数
        y = self.layer2(y)
        y = torch.sigmoid(y)
        return y
```
编写完成后记得保存，在同目录下运行以下代码：
```python
import torch
# 调用perception.py下的Perception
from perception import Perception
# 实例化一个网络，并赋值全连接中的维数，最终输出二维代表了二分类
perception = Perception(2,3,2)

perception  # 可以看到perception中包含上述定义的layer1与layer2
Out[114]: 
Perception(
  (layer1): Linear()
  (layer2): Linear()
)
# named_parameters()可以返回学习参数的迭代器，分别为参数名与参数值
for name,parameter in perception.named_parameters():
    print(name, parameter)


layer1.w Parameter containing:
tensor([[ 1.7656,  1.0378, -0.1398],
        [ 0.0067,  0.6684, -0.9848]], requires_grad=True)
layer1.b Parameter containing:
tensor([ 0.3884, -1.6738,  0.6867], requires_grad=True)
layer2.w Parameter containing:
tensor([[ 1.8342,  1.8933],
        [-0.0994, -1.1779],
        [-0.0820,  0.5330]], requires_grad=True)
layer2.b Parameter containing:
tensor([0.6285, 0.3273], requires_grad=True)

data = torch.randn(4,2)

data
Out[117]: 
tensor([[-1.6903,  0.8481],
        [ 0.7108, -1.1896],
        [ 1.2353, -1.7754],
        [-0.4795, -1.1181]])

output = perception(data)

output
Out[119]: 
tensor([[0.6700, 0.6624],
        [0.8888, 0.8993],
        [0.9037, 0.9142],
        [0.7790, 0.8112]], grad_fn=<SigmoidBackward>)
```



