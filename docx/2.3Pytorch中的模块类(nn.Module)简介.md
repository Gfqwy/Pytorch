### 1. 模块的模型和使用示例
模块在Pytorch深度学习模型的搭建过程中扮演者重要的角色，模块本身是一个类nn.Module，PyTorch的模型通过继承该类，在类的内部定义好模 的实例化（即：在初始化中定义模型结构与参数），通过前向计算调用子模块（在函数forward()中编写网络前向过程），最后实现深度学习模型的搭建，模块类的构建模型请看以下代码。

```python
import torch
import torch.nn as nn

class Model(nn.Module):
    def __init__(self, ...): # 定义类的初始化函数，...是用户的传入参数
        super(Model, self).__init__()
        ... # 根据传入的参数来定义子模块
    
    def forward(self, ...): # 定义前向计算的输入参数，...一般是张量或者其他的参数
        ret = ... # 根据传入的张量和子模块计算返回张量
        return ret
```
下面以一个由两个全连接层组成的感知机为例，介绍如何使用nn.Module构造模块化的神经网络。新建一个`perception.py`文件，内容如下：
```python
# -*- coding: utf-8 -*-
import torch
from torch import nn


# 首先建立一个全连接的子module，继承nn.Module
class Linear(nn.Module):
    def __init__(self, in_dim, out_dim):
        super(Linear, self).__init__()  # 调用nn.Module的构造函数
        # 使用nn.Parameter来构造需要学习的参数
        self.w = nn.Parameter(torch.randn(in_dim, out_dim))
        self.b = nn.Parameter(torch.randn(out_dim))

# 在forward中实现前向传播过程
    def forward(self, x):
        x = x.matmul(self.w)  # 使用Tensor.matmul实现矩阵相乘
        y = x + self.b.expand_as(x)  # 使用Tensor.expand_as()来保证矩阵形状一致
        # print('Linear.forward:', y)
        return y


# 构建感知机类，继承nn.Module，并调用了Linear的子module
class Perception(nn.Module):
    def __init__(self, in_dim, hid_dim, out_dim):
        super(Perception, self).__init__()
        self.layer1 = Linear(in_dim, hid_dim)
        self.layer2 = Linear(hid_dim, out_dim)

    def forward(self, x):
        x = self.layer1(x)    # 结果输出：Linear里的forward的return y，可通过下一行代码查看
        # print('对比Linear.forward输出的值:', x)
        y = torch.sigmoid(x)  # 使用torch中的sigmoid作为激活函数
        y = self.layer2(y)    # 把使用了激活的x(即y)作为输入放到Linear的forward中得到新的y
        # print('对比最新的Linear.forward输出的值:', y)
        y2 = torch.sigmoid(y) # 使用torch中的sigmoid作为激活函数
        return y2  # 传入的参数，进行了两次的（wx+b 和 激活函数）

```
编写完成后记得保存，在同级目录下新建`perception_test.py`文件，内容如下：
```python
# -*- coding: utf-8 -*-
# 调用Perception函数
import torch
from perception import Perception
# 实例化一个网络，并赋值全连接中的维数，最终输出二维代表了二分类
perception = Perception(2, 3, 2)
# named_parameters()可以返回学习参数的迭代器，分别为参数名与参数值
for name,parameter in perception.named_parameters():
    print(name, parameter)
data = torch.rand(4, 2)
output = perception(data)
print(output)
```
### 2. 函数的讲解
##### 2.1 nn.Parameter函数
在类的__init__()中需要定义网络学习的参数，在此使用`nn.Parameter()`函数定义了全连接中的$ω$和$b$，这是一种特殊的Tensor的构造方法，`默认需要求导`，即requires_grad为True。

##### 2.2 forward()函数与反向传播
forward()函数用来进行网络的前向传播，并需要传入相应的Tensor，例如上例的perception(data)即是直接调用了forward()。在具体底层实现中，perception.__call__(data)将类的实例perception变成了可调用对象perception(data)，而在perception.__call__(data)中主要调用了forward()函数。 
nn.Module可以自动利用Autograd机制实现反向传播，不需要自己手动实现。
##### 2.3 多个Module的嵌套
在Module的搭建时，可以嵌套包含子Module，上例的Perception中 调用了Linear这个类，这样的代码分布可以使网络更加模块化，提升代码的复用性。
在上例中，Perception中调用一次Linear，输出结果就是return中的y；用代码解释，就是，`x = self.layer1(x)`返回的是经过前向传播后的值，而`y = self.layer2(y)`则是x经过前向传播后经过激活函数处理后再一次经过前向传播。
##### 2.4 nn.Module与nn.functional库
在PyTorch中，还有一个库为nn.functional，同样也提供了很多网络层与函数功能，但与nn.Module不同的是，`利用nn.functional定义的网络层不可自动学习参数，还需要使用nn.Parameter封装`。nn.functional的设计初衷是对于一些不需要学习参数的层，如激活层、BN（Batch Normalization）层，可以使用nn.functional，这样这些层就不需要在nn.Module中定义了。 
总体来看，`对于需要学习参数的层，最好使用nn.Module，对于无参数学习的层，可以使用nn.functional`，当然这两者间并没有严格的好坏之分。

##### 2.5 nn.Sequential()模块
`当模型中只是简单的前馈网络时，即上一层的输出直接作为下一层 的输入，这时可以采用nn.Sequential()模块来快速搭建模型`，而不必手动在forward()函数中一层一层地前向传播。因此，如果想快速搭建模型而不考虑中间过程的话，推荐使用nn.Sequential()模块。
在上面的例子中，Perception类中的layer1与layer2是直接传递的， 因此该Perception类可以使用nn.Sequential()快速搭建。在此新建一个 `perception_sequential.py`文件，内容如下：
```python
# -*- coding: utf-8 -*-
from torch import nn


class Peception(nn.Module):
    def __init__(self, in_dim, hid_dim, out_dim):
        super(Peception, self).__init__()
        # 利用nn.Sequential()快速搭建网络模块
        self.layer = nn.Sequential(
            nn.Linear(in_dim, hid_dim),
            nn.Sigmoid(),
            nn.Linear(hid_dim, out_dim),
            nn.Sigmoid()
            )

        def forward(self, x):
            y = self.layer(x)
            return y
```
编写完成后保存，在同级目录下新建`perception_sequential_test.py`文件，内容如下：
```python
# -*- coding: utf-8 -*-
import torch
from perception_sequential import Perception
model = Perception(100, 1000, 10)  # 构建类的实例
print(model)  # 打印model结构，会显示Sequential中每一层的具体参数配置

data = torch.randn(100)
output = model(data)
print(output)
print(output.shape)
```

